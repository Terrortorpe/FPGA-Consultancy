# Quantisation (Wenlin Yi)
<font size = 4>
Quantisation is applied to the original EPSCN Tensorflow code. There are two quantisation methodes compared to non-quantised model: Quantisation Aware Training(QAT) and post-training quantisation. The different quantised word lengths and data types are also tested. And for the QAT, quantisation on different layers/combination of layers are compared with their peak signal-noise ratio.

## Libraries

<font size = 4>

- QAT library:

- Post-training quantisation library:

## Models
<font size = 4>
  
- Baseline model:
  
- QAT models:
  
- Post training quantised model:

## Performances
<font size = 4>
  
- Performance Metric:
  
- Training Performance Graph:
  
  (random seed:1337)
