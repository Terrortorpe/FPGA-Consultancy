# Super_Resolution_Models (Peter Barabas)

The PYNQ-Z1 board is designed to be used with PYNQ, an open-source framework that enables embedded programmers to exploit the capabilities of Xilinx Zynq All Programmable SoCs (APSoCs) without having to design programmable logic circuits. Instead the APSoC is programmed using Python, with the code developed and tested directly on the PYNQ-Z1. The programmable logic circuits are imported as hardware libraries and programmed through their APIs in essentially the same way that the software libraries are imported and programmed.

The Python ecosystem has many machine learning frameworks to speed up the development and testing of machine learning applications such as neural networks. In recent years neural networks have proven to be an easy to use and highly effective machine learning method, with the advent of specialised hardware, training neural nets became much faster which enabled researchers to use much bigger networks to tackle problems. One such problem was image processing, more specifically synthetically enhancing the quality of images that have already been taken or generated, by upscaling them to a higher resolution.

There are more than one methods to upscale images using neural networks. For example in a video context, the algorithm may use more than one frame, therefore extracting some temporal data on how objects move between frames in order to improve accuracy. As a proof of concept we chose a method that does not rely on temporal data, thereby reducing complexity but also accuracy. The only input to this network is the low resolution image we want to upscale, and the only output is the upscaled image.

The network we use is based on this paper: [Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network] (https://arxiv.org/abs/1609.05158)
